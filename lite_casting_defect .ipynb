{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The quality of casting is crucial in ensuring the safety and reliability of engineering structures. \n",
        "\n",
        "Casting defects can occur during the manufacturing process, leading to compromised performance, reduced durability, and potentially catastrophic failures. Automated defect detection using computer vision techniques is a promising solution to address this issue. \n",
        "\n",
        "In this project, I propose a **simple convolutional neural network (CNN) model for binary classification of casting defects**. This model is designed to classify castings as either defective or non-defective based on images captured during the production process and it achieved 97.5% acuuracy and 97.4% F-1 score.\n",
        "\n",
        "For this work I used a \"casting product image data for quality inspection\" dataset which contains 6633 already augmented images of front view of a casting product in the train set, and 715 respective images in the test set.\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/ravirajsinh45/real-life-industrial-dataset-of-casting-product\n"
      ],
      "metadata": {
        "id": "LU96Tu_FM8e4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fs_AFnA-Gmm"
      },
      "outputs": [],
      "source": [
        "#Importing all of the relevant libraries and modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "\n",
        "import torchinfo\n",
        "\n",
        "from torcheval import metrics\n",
        "\n",
        "import os\n",
        "\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm.auto import tqdm "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device-agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "-X_2_rTxJ-on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path to image folder\n",
        "main_path = Path('/content/drive/MyDrive/casting_defects/casting_data')\n",
        "# Checking if the image folder exists\n",
        "if main_path.is_dir():\n",
        "  print(f\"{main_path} directory exists\")"
      ],
      "metadata": {
        "id": "hei-thLezlVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the train and test paths\n",
        "train_path = main_path / 'train'\n",
        "test_path = main_path / 'test'\n",
        "train_path, test_path"
      ],
      "metadata": {
        "id": "7nQz3Wr3ztRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To inspect what is in our data directory we will use Python's in-built \"os.walk()\"\n",
        "def walk_through_dir(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")\n",
        "    \n",
        "walk_through_dir(main_path)"
      ],
      "metadata": {
        "id": "0-jNi1ayKBz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "random.seed(77)\n",
        "\n",
        "# Get all image paths\n",
        "main_path_list = list(main_path.glob(\"*/*/*.jpeg\"))\n",
        "\n",
        "# Get random image path\n",
        "random_image_path = random.choice(main_path_list)\n",
        "\n",
        "# Get image class from path name of the image\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# Print metadata of the image\n",
        "print(f'Random image path: {random_image_path}')\n",
        "print(f'Image class: {image_class}')\n",
        "print(f'Image height: {img.height}')\n",
        "print(f'Image width: {img.width}')\n",
        "img\n"
      ],
      "metadata": {
        "id": "sqVR81GXKGsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation of the image\n",
        "data_transform = torchvision.transforms.Compose([\n",
        "    # Drop 2 channels, since the original images are gray-scaled\n",
        "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
        "    # Resizing the images to 64 x 64\n",
        "    torchvision.transforms.Resize(size = (64,64)),\n",
        "    # Turn images into tensors\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    # Normalize the inputs\n",
        "    torchvision.transforms.Normalize(mean = 0.5642, std = 0.2273)\n",
        "])"
      ],
      "metadata": {
        "id": "QLN76HKLKIk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And now we will create a dataset using tochvisiom.datasets.ImageFolder\n",
        "train_data = torchvision.datasets.ImageFolder(root = train_path, #targer folder of imgs\n",
        "                                  transform = data_transform, #perform data_transform on images\n",
        "                                  target_transform = None) #transforms to perform on labels\n",
        "\n",
        "test_data = torchvision.datasets.ImageFolder(root = test_path, #targer folder of imgs\n",
        "                                  transform = data_transform, #perform data_transform on images\n",
        "                                  target_transform = None) #transforms to perform on labels\n",
        "\n",
        "print(f\"Train data: \\n{train_data}\")\n",
        "print(f\"Test data: \\n{test_data}\")"
      ],
      "metadata": {
        "id": "e1bkgyp7KKDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block of code below was used to find the mean and std of the original tensors for normalization\n",
        "It was run before creating a Normalization data transformation"
      ],
      "metadata": {
        "id": "ftwh4ZL5AMZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageStat\n",
        "class Stats(ImageStat.Stat):\n",
        "  def __add__(self, other):\n",
        "    # add self.h and other.h element-wise\n",
        "    return Stats(list(np.add(self.h, other.h)))\n",
        "\n",
        "loader = DataLoader(train_data, batch_size=8, num_workers=os.cpu_count()) #Creating a dataloader to calculate mean and std\n",
        "\n",
        "statistics = None\n",
        "\n",
        "for batch,(X,y) in enumerate(loader):\n",
        "  for x in X:\n",
        "    if statistics is None:\n",
        "      statistics = Stats(torchvision.transforms.functional.to_pil_image(x))\n",
        "    else:\n",
        "      statistics += Stats(torchvision.transforms.functional.to_pil_image(x))\n",
        "\n",
        "print(statistics.mean[0]/255)\n",
        "print(statistics.stddev[0]/255.)\n",
        "  "
      ],
      "metadata": {
        "id": "aQRjhNYbYILY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and indices\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "id": "kV4kL5SxKL5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the lengths of train and test sets\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "_rs0YgHjKNJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating two dataloaders\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "print(f'Batch size: {BATCH_SIZE} and num_of_workers: {NUM_WORKERS}')\n",
        "train_dataloader = DataLoader(dataset = train_data,\n",
        "                               batch_size = BATCH_SIZE,\n",
        "                               num_workers = NUM_WORKERS,\n",
        "                               shuffle = True)\n",
        "test_dataloader = DataLoader(dataset = test_data,\n",
        "                               batch_size = BATCH_SIZE,\n",
        "                               num_workers = NUM_WORKERS)\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "tX4ziGWgKOXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking that the shape of the tensor is correct\n",
        "img, label = next(iter(train_dataloader))\n",
        "img.shape"
      ],
      "metadata": {
        "id": "g-8ajwHKKQZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LiteModel(nn.Module):\n",
        "  def __init__(self, input_channels:int, output_shape:int, num_of_kernels:int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = input_channels,\n",
        "                  out_channels = num_of_kernels,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Dropout2d(),\n",
        "        nn.Conv2d(in_channels = num_of_kernels,\n",
        "                  out_channels = num_of_kernels,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = num_of_kernels,\n",
        "                  out_channels = num_of_kernels,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = 16 * 16 * num_of_kernels,\n",
        "                  out_features = 16*16*num_of_kernels),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(in_features = 16*16*num_of_kernels,\n",
        "                  out_features = output_shape)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "8afiicvGK0RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a model\n",
        "torch.manual_seed(77)\n",
        "model = LiteModel(input_channels = 1,\n",
        "                  num_of_kernels =10,\n",
        "                  output_shape = len(train_data.classes)).to(device)"
      ],
      "metadata": {
        "id": "hofnSSLDUQFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting detailed summary of the model using torchinfo's summary() method\n",
        "torchinfo.summary(model, input_size=[1,1,64,64])"
      ],
      "metadata": {
        "id": "hidnBk27Una9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if the model is built correctly and it's giving predictions\n",
        "img_batch, label_batch = next(iter(train_dataloader))\n",
        "img_single, label_single = img_batch[0], label_batch[0]\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  pred = model(img_single.unsqueeze(dim = 0).to(device))\n",
        "pred, label_single"
      ],
      "metadata": {
        "id": "uP0ndm3vU7eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model : nn.Module,\n",
        "               train_dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "  train_loss, train_acc = 0,0 \n",
        "  model.train() # Putting the model in a train mode\n",
        "\n",
        "  for batch, (X,y) in enumerate(train_dataloader):\n",
        "    X, y = X.to(device), y.to(device) # Sending tensors to the device\n",
        "    # Forward pass\n",
        "    y_hat = model(X)\n",
        "    # Calculate and accumulate the loss\n",
        "    loss = loss_fn(y_hat, y)\n",
        "    train_loss += loss.item()\n",
        "    # Optimizer zero-grad\n",
        "    optimizer.zero_grad()\n",
        "    # Backprop\n",
        "    loss.backward()\n",
        "    # Optimizer step\n",
        "    optimizer.step()\n",
        "    # Calculating and accumulating accuracy\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_hat, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class == y).sum().item() / len(y_hat)\n",
        "  # Averaging out the loss and accuracy\n",
        "  train_loss = train_loss / len(train_dataloader)\n",
        "  train_acc = train_acc / len(train_dataloader)\n",
        "\n",
        "  return train_loss, train_acc\n"
      ],
      "metadata": {
        "id": "rIImX8lFTsFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: nn.Module,\n",
        "              test_dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: nn.Module):\n",
        "  test_loss, test_acc = 0,0\n",
        "  model.eval() #Putting a model in a test mode\n",
        "  for batch, (X,y) in enumerate(test_dataloader):\n",
        "    X, y = X.to(device), y.to(device) # Sending tensors to the device\n",
        "    # Forward pass\n",
        "    y_hat = model(X)\n",
        "    # Calculating a loss\n",
        "    loss = loss_fn(y_hat, y)\n",
        "    # Accumulating a loss\n",
        "    test_loss += loss.item()\n",
        "    # Calculating and accumulating accuracy\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_hat, dim=1), dim=1)\n",
        "    test_acc += (y_pred_class == y).sum().item() / len(y_hat)\n",
        "  # Averaging out the loss and accuracy\n",
        "  test_loss = test_loss / len(test_dataloader)\n",
        "  test_acc = test_acc / len(test_dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n"
      ],
      "metadata": {
        "id": "SoQe6_AozY_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: nn.CrossEntropyLoss(),\n",
        "          scheduler: torch.optim.lr_scheduler,\n",
        "          epochs: int):\n",
        "  # Creating a dictionary to track model's performance\n",
        "  results = {\"train_loss\":[],\n",
        "             \"train_accuracy\":[],\n",
        "             'test_loss':[],\n",
        "             'test_accuracy':[]}\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model = model, train_dataloader = train_dataloader, loss_fn = loss_fn, optimizer = optimizer)\n",
        "    scheduler.step(train_acc) # Step of the learning rate scheduler\n",
        "    current_lr = scheduler.state_dict()['_last_lr'][0] # Loading current learning rate\n",
        "    test_loss, test_acc = test_step(model = model, test_dataloader = test_dataloader, loss_fn = loss_fn)\n",
        "    print(f'Epoch:{epoch + 1} // Train loss:{train_loss:.4f} // Train accuracy: {train_acc:.4f} // Test loss:{test_loss:.4f} // Test accuracy: {test_acc:.4f} // Learning rate:{current_lr}')\n",
        "\n",
        "    # Appending the \"results\" dictionary\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['train_accuracy'].append(train_acc)\n",
        "    results['test_loss'].append(test_loss)\n",
        "    results['test_accuracy'].append(test_acc)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "VNiTTMGkYC0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss() # Setting up the loss function\n",
        "optimizer = torch.optim.Adam(params =model.parameters(), lr = 0.001) # Settng up the optimizer\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer = optimizer, factor=0.5, patience = 3) #Setting up the lr scheduler\n",
        "EPOCHS = 20 # Number of epochs"
      ],
      "metadata": {
        "id": "UKiAQtW_KCG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = train(model= model, train_dataloader = train_dataloader,\n",
        "                test_dataloader = test_dataloader,\n",
        "                optimizer = optimizer, scheduler = scheduler,\n",
        "                loss_fn = loss_fn, epochs = EPOCHS)"
      ],
      "metadata": {
        "id": "o0WKRoyhKN2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to plot the loss curves\n",
        "def plot_loss_curves(results):\n",
        "    \n",
        "    # Get the loss values of the results dictionary (training and test)\n",
        "    train_loss = results['train_loss']\n",
        "    test_loss = results['test_loss']\n",
        "    # Get the accuracy values of the results dictionary (training and test)\n",
        "    train_accuracy = results['train_accuracy']\n",
        "    test_accuracy = results['test_accuracy']\n",
        "\n",
        "    # Figure out how many epochs there were\n",
        "    epochs = range(len(results['train_loss']))\n",
        "\n",
        "    # Setup a plot \n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, test_loss, label='test_loss')\n",
        "    plt.plot(epochs, train_loss, label='train_loss')\n",
        "    \n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
        "    plt.plot(epochs, train_accuracy, label='train_accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend();"
      ],
      "metadata": {
        "id": "nOmCrneYO4AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(results)"
      ],
      "metadata": {
        "id": "7_w0zNdLQwh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to calculate F-1 score of our model\n",
        "def f1_score(model: nn.Module,\n",
        "             test_dataloader: torch.utils.data.DataLoader):\n",
        "  y_pred_class = []\n",
        "  # Making predictions\n",
        "  model.eval()\n",
        "  for batch, (X,y) in enumerate(test_dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_hat = model(X)\n",
        "    y_pred_class += torch.argmax(torch.softmax(y_hat, dim=1), dim=1)\n",
        " \n",
        "  # Turning 2 lists into tensors  \n",
        "  y_target =torch.FloatTensor(test_dataloader.dataset.targets)\n",
        "  y_input = torch.FloatTensor(y_pred_class)\n",
        "\n",
        "  return metrics.functional.multiclass_f1_score(input = y_input, target = y_target)"
      ],
      "metadata": {
        "id": "drq5tX3XGfO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(model, test_dataloader)"
      ],
      "metadata": {
        "id": "-_Uv-5DMGnTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model's state_dict and checking if it is loading successfully"
      ],
      "metadata": {
        "id": "1F-rjgX-EX2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create models directory \n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path \n",
        "MODEL_NAME = \"gear_defect_classifier.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state dict \n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "IpYesMM1DpA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating a new model and loading parameters\n",
        "new_model = LiteModel(input_channels = 1,\n",
        "                  num_of_kernels =10,\n",
        "                  output_shape = len(train_data.classes)).to(device)\n",
        "\n",
        "new_model.load_state_dict(torch.load('models/gear_defect_classifier.pth'))"
      ],
      "metadata": {
        "id": "Gz4ajACaEBi7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}